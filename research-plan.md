# LightningGrep ç ”ç©¶æ–¹æ¡ˆ

> **é¦–ä¸ªå¼€æºçš„å¹¶è¡Œæ£€ç´¢å°æ¨¡å‹**
> 
> åˆ›å»ºæ—¶é—´ï¼š2025-12-22
> 
> çŠ¶æ€ï¼šğŸŸ¢ æ‰§è¡Œä¸­

---

## ä¸€ã€é¡¹ç›®å®šä½

### 1.1 Slogan

> **LightningGrep: The First Open-Source Parallel Retrieval Model for Small LLMs**

### 1.2 æ ¸å¿ƒç›®æ ‡

1. **å®Œå…¨å¼€æº**ï¼šæ¨¡å‹æƒé‡ + è®­ç»ƒä»£ç  + åˆæˆæ•°æ® + è¯„æµ‹è„šæœ¬
2. **å°æ¨¡å‹æé™**ï¼šç”¨ 1.7B æŒ‘æˆ˜ 3B+ æ¨¡å‹çš„æ€§èƒ½
3. **æ–¹æ³•å¯¹é½**ï¼šå¤ç° SWE-grep æ ¸å¿ƒæ–¹æ³• + æ”¹è¿›
4. **å¯å¤ç°**ï¼šç¤¾åŒºå¯ä»¥ä¸€é”®å¤ç°æˆ‘ä»¬çš„ç»“æœ

### 1.3 å½±å“åŠ›æ¥æº

| æ¥æº | è¯´æ˜ |
|------|------|
| **å¡«è¡¥ç©ºç™½** | ç›®å‰æ— å¼€æºå¹¶è¡Œæ£€ç´¢æ¨¡å‹ï¼ˆSWE-grep é—­æºï¼ŒParallelSearch æœªå…¬å¼€ï¼‰ |
| **å°æ¨¡å‹æé™** | 1.7B vs GAP-3Bï¼Œæ¢ç´¢å°æ¨¡å‹èƒ½åŠ›è¾¹ç•Œ |
| **å®Œæ•´å¼€æº** | ä¸åªæ˜¯æ¨¡å‹ï¼Œè®­ç»ƒå…¨æµç¨‹å¯å¤ç° |

### 1.4 å¼€æºæ¸…å•

| äº§å‡º | å¹³å° | çŠ¶æ€ |
|------|------|------|
| æ¨¡å‹æƒé‡ | HuggingFace | â³ å¾…å®Œæˆ |
| è®­ç»ƒä»£ç  | GitHub | â³ å¾…å®Œæˆ |
| åˆæˆæ•°æ® | HuggingFace Datasets | â³ å¾…å®Œæˆ |
| è¯„æµ‹è„šæœ¬ | GitHub | â³ å¾…å®Œæˆ |
| æŠ€æœ¯æŠ¥å‘Š | arXiv / GitHub | â³ å¾…å®Œæˆ |

---

## äºŒã€å…³é”®å†³ç­–

### 2.1 åŸºåº§æ¨¡å‹

| é€‰é¡¹ | å‚æ•°é‡ | å†³ç­– | ç†ç”± |
|------|--------|------|------|
| Qwen3-0.6B | 0.6B | éªŒè¯å®éªŒ | å¿«é€ŸéªŒè¯æ–¹æ¡ˆå¯è¡Œæ€§ï¼ŒèŠ‚çœèµ„æº |
| Qwen3-1.7B | 1.7B | æœ€ç»ˆç›®æ ‡ | ç”¨æˆ·æŒ‡å®šï¼Œå°å‹åŒ–ç›®æ ‡ |
| Qwen2.5-3B | 3B | å¤‡é€‰ | GAP å·²éªŒè¯æœ‰æ•ˆï¼Œå¦‚æœ 1.7B ä¸å¤Ÿåˆ™å‡çº§ |

**ç­–ç•¥**ï¼š0.6B éªŒè¯ â†’ 1.7B æ­£å¼è®­ç»ƒ â†’ 3B å¤‡é€‰

### 2.2 è¯„æµ‹åœºæ™¯

**é€‰æ‹©**ï¼šé€šç”¨ QAï¼ˆHotpotQA ä¸ºä¸»ï¼‰

**ç†ç”±**ï¼š
- å…¬å¼€æ•°æ®é›†ï¼Œå¯å¤ç°
- GAPã€ParallelSearch éƒ½æœ‰å…¬å¼€åˆ†æ•°ï¼Œå¯ç›´æ¥å¯¹æ¯”
- æ¯”ä»£ç æ£€ç´¢æ›´å®¹æ˜“æ„å»ºæ•°æ®

### 2.3 åˆ›æ–°ç‚¹

**åˆ†é˜¶æ®µå¼•å…¥**ï¼Œé™ä½é£é™©ï¼š

| ç‰ˆæœ¬ | åˆ›æ–°ç‚¹ | å¤æ‚åº¦ | å¯¹æ ‡ |
|------|--------|--------|------|
| V1 | å¹¶è¡Œæ£€ç´¢ï¼ˆå¤ç°æ ¸å¿ƒï¼‰ | ä½ | ParallelSearch |
| V2 | + è¡Œå·å¬å› | ä¸­ | SWE-grep |
| V3 | + ç½®ä¿¡åº¦åŠ¨æ€ç»ˆæ­¢ | é«˜ | ç‹¬åˆ› |

---

## ä¸‰ã€æŠ€æœ¯æ–¹æ¡ˆ

### 3.1 æ¨¡å‹è¾“å‡ºæ ¼å¼

**V1 æ ¼å¼**ï¼ˆå¯¹é½ ParallelSearchï¼‰ï¼š
```
<think>åˆ†æé—®é¢˜ï¼Œè¯†åˆ«å¯å¹¶è¡Œçš„å­é—®é¢˜</think>
<search>å­é—®é¢˜1 ## å­é—®é¢˜2 ## å­é—®é¢˜3</search>
<information>æœç´¢ç»“æœ1</information>
<information>æœç´¢ç»“æœ2</information>
<think>ç»¼åˆä¿¡æ¯ï¼Œå¾—å‡ºç­”æ¡ˆ</think>
<answer>æœ€ç»ˆç­”æ¡ˆ</answer>
```

**V2 æ ¼å¼**ï¼ˆåŠ å…¥è¡Œå·ï¼‰ï¼š
```
<think>åˆ†æé—®é¢˜</think>
<search>å­é—®é¢˜1 ## å­é—®é¢˜2</search>
<information>æœç´¢ç»“æœ1</information>
<information>æœç´¢ç»“æœ2</information>
<answer>
æœ€ç»ˆç­”æ¡ˆ
<sources>
  <source file="doc1.txt" lines="15-20"/>
  <source file="doc2.txt" lines="42-45"/>
</sources>
</answer>
```

**V3 æ ¼å¼**ï¼ˆåŠ å…¥ç½®ä¿¡åº¦ï¼‰ï¼š
```
<round id="1">
  <think>åˆ†æé—®é¢˜</think>
  <search>å­é—®é¢˜1 ## å­é—®é¢˜2</search>
  <confidence>0.4</confidence>
</round>
<information>æœç´¢ç»“æœ</information>
<round id="2">
  <think>éœ€è¦æ›´å¤šä¿¡æ¯</think>
  <search>å­é—®é¢˜3</search>
  <confidence>0.9</confidence>
</round>
<information>æœç´¢ç»“æœ</information>
<terminate reason="high_confidence"/>
<answer>æœ€ç»ˆç­”æ¡ˆ</answer>
```

### 3.2 å·¥å…·ç¯å¢ƒ

**æ ¸å¿ƒç»„ä»¶**ï¼šæ¨¡å‹ä¸æ˜¯ç›´æ¥è¾“å‡ºç­”æ¡ˆï¼Œè€Œæ˜¯ä¸å·¥å…·ç¯å¢ƒäº¤äº’ã€‚

**äº¤äº’æµç¨‹**ï¼š
```
ç”¨æˆ·é—®é¢˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ¨¡å‹ç”Ÿæˆ: <search>query1 ## query2</search>     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ è§£æå¹¶è¡ŒæŸ¥è¯¢
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å·¥å…·ç¯å¢ƒ: å¹¶è¡Œæ‰§è¡Œ search(query1), search(query2)â”‚
â”‚  è¿”å›: <information>ç»“æœ1</information>          â”‚
â”‚        <information>ç»“æœ2</information>          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ æ‹¼æ¥åˆ°ä¸Šä¸‹æ–‡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ¨¡å‹ç»§ç»­ç”Ÿæˆ: <think>...</think><answer>...</answer> â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å·¥å…·é›†å®šä¹‰**ï¼š

| å·¥å…· | åŠŸèƒ½ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| `search(query)` | æœç´¢æ–‡æ¡£ | æŸ¥è¯¢å­—ç¬¦ä¸² | ç›¸å…³æ®µè½åˆ—è¡¨ |
| `read(doc_id, start, end)` | è¯»å–æŒ‡å®šè¡Œ | æ–‡æ¡£ID + è¡ŒèŒƒå›´ | æ–‡æ¡£å†…å®¹ |

**æœç´¢åç«¯é€‰æ‹©**ï¼š

| é€‰é¡¹ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨è |
|------|------|------|------|
| **BM25** | ç®€å•ã€å¿«é€Ÿã€æ— éœ€ GPU | è¯­ä¹‰ç†è§£å¼± | âœ… V1 ä½¿ç”¨ |
| **Contriever** | è¯­ä¹‰æ£€ç´¢ | éœ€è¦ GPU | V2 å¯é€‰ |
| **ColBERT** | æ•ˆæœå¥½ | å¤æ‚ | æš‚ä¸è€ƒè™‘ |

**V1 å®ç°**ï¼ˆæœ€ç®€æ–¹æ¡ˆï¼‰ï¼š
```python
from rank_bm25 import BM25Okapi

class SearchEnvironment:
    def __init__(self, corpus):
        # corpus: List[Dict] with {"doc_id", "content", "sentences"}
        self.corpus = corpus
        self.tokenized = [doc["content"].split() for doc in corpus]
        self.bm25 = BM25Okapi(self.tokenized)
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """è¿”å›æœ€ç›¸å…³çš„ top_k ä¸ªæ®µè½"""
        scores = self.bm25.get_scores(query.split())
        top_indices = scores.argsort()[-top_k:][::-1]
        results = []
        for idx in top_indices:
            doc = self.corpus[idx]
            results.append({
                "doc_id": doc["doc_id"],
                "content": doc["content"][:500],  # æˆªæ–­
                "score": scores[idx]
            })
        return results
    
    def read(self, doc_id: str, start: int, end: int) -> str:
        """è¯»å–æŒ‡å®šæ–‡æ¡£çš„æŒ‡å®šè¡Œ"""
        for doc in self.corpus:
            if doc["doc_id"] == doc_id:
                lines = doc["content"].split("\n")
                return "\n".join(lines[start:end])
        return ""
```

**HotpotQA çš„ Corpus æ„å»º**ï¼š
```python
def build_corpus_from_hotpotqa(sample):
    """ä» HotpotQA æ ·æœ¬æ„å»ºæœç´¢è¯­æ–™åº“"""
    corpus = []
    for title, sentences in sample["context"]:
        corpus.append({
            "doc_id": title,
            "content": "\n".join(sentences),
            "sentences": sentences
        })
    return corpus
```

**å¹¶è¡Œæ‰§è¡Œ**ï¼š
```python
import concurrent.futures

def parallel_search(queries: List[str], env: SearchEnvironment) -> List[Dict]:
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæœç´¢æŸ¥è¯¢"""
    with concurrent.futures.ThreadPoolExecutor() as executor:
        results = list(executor.map(env.search, queries))
    return results
```

### 3.3 RL è®­ç»ƒä¸­çš„äº¤äº’å¾ªç¯

**å®Œæ•´çš„ Episode æµç¨‹**ï¼š
```python
def run_episode(model, env, question, max_rounds=4):
    """è¿è¡Œä¸€ä¸ªå®Œæ•´çš„æ£€ç´¢ Episode"""
    context = f"Question: {question}\n"
    trajectory = []
    
    for round_id in range(max_rounds):
        # 1. æ¨¡å‹ç”Ÿæˆï¼ˆå¯èƒ½åŒ…å«å¹¶è¡Œæœç´¢ï¼‰
        output = model.generate(context, stop_tokens=["</search>", "</answer>"])
        trajectory.append({"type": "model", "content": output})
        
        # 2. è§£æè¾“å‡º
        if "<search>" in output:
            # æå–å¹¶è¡ŒæŸ¥è¯¢ï¼ˆç”¨ ## åˆ†éš”ï¼‰
            search_content = extract_between(output, "<search>", "</search>")
            queries = [q.strip() for q in search_content.split("##")]
            
            # 3. å¹¶è¡Œæ‰§è¡Œæœç´¢
            results = parallel_search(queries, env)
            
            # 4. æ ¼å¼åŒ–è¿”å›ç»“æœ
            info_block = ""
            for i, (query, result) in enumerate(zip(queries, results)):
                info_block += f"<information query=\"{query}\">\n"
                for doc in result:
                    info_block += f"[{doc['doc_id']}]: {doc['content']}\n"
                info_block += "</information>\n"
            
            # 5. æ‹¼æ¥åˆ°ä¸Šä¸‹æ–‡
            context += output + "\n" + info_block
            trajectory.append({"type": "tool", "content": info_block})
        
        elif "<answer>" in output:
            # æ£€ç´¢å®Œæˆï¼Œæå–ç­”æ¡ˆ
            answer = extract_between(output, "<answer>", "</answer>")
            context += output
            break
    
    return {
        "trajectory": trajectory,
        "final_answer": answer,
        "rounds": round_id + 1,
        "search_count": sum(1 for t in trajectory if t["type"] == "tool")
    }
```

**å¥–åŠ±è®¡ç®—æ—¶æœº**ï¼šEpisode ç»“æŸåï¼Œæ ¹æ®æœ€ç»ˆç­”æ¡ˆå’Œè½¨è¿¹è®¡ç®—å¥–åŠ±ã€‚

### 3.4 è®­ç»ƒç®—æ³•ï¼ˆå¯¹é½ SWE-grepï¼‰

**æ ¸å¿ƒï¼šPer-Sequence Importance Sampling + Leave-One-Out Baseline**

SWE-grep åšå®¢å…¬å¼€çš„ Loss å‡½æ•°ï¼š
```
L(Î¸) = -1/(GÂ·Tmax) Î£â±¼â‚Œâ‚á´³ [âˆáµ¢â‚Œâ‚áµ€Ê² (Ï€_trainer(aâ±¼,áµ¢|sâ±¼,áµ¢) / Ï€_sampler(aâ±¼,áµ¢|sâ±¼,áµ¢))]_âˆ‡ 
       Ã— Î£â‚œâ‚Œâ‚áµ€Ê² (Ï€_trainer(aâ±¼,â‚œ|sâ±¼,â‚œ) / [Ï€_trainer(aâ±¼,â‚œ|sâ±¼,â‚œ)]_âˆ‡) Ã— Aâ±¼
```

å…¶ä¸­ï¼š
- `G`ï¼šåŒä¸€ prompt çš„é‡‡æ ·æ•°
- `Tmax`ï¼šæœ€å¤§ token æ•°
- `Aâ±¼ = Râ±¼ - mean(Râ‚...R_G)`ï¼šLeave-One-Out Baseline
- `[Â·]_âˆ‡`ï¼šstop gradient
- `Ï€_trainer`ï¼šè®­ç»ƒæ—¶çš„ç­–ç•¥
- `Ï€_sampler`ï¼šé‡‡æ ·æ—¶çš„ç­–ç•¥

**ç¨³å®šæ€§æŠ€å·§**ï¼ˆSWE-grep åšå®¢å…¬å¼€ï¼‰ï¼š
1. Mask è¿‡é•¿è½¨è¿¹
2. Mask æç«¯ IS ratio
3. ç§»é™¤ Format Rewardï¼ˆæ ¼å¼é”™ç›´æ¥ 0 åˆ†ï¼‰
4. æŒ‰å¹³å‡å·¥å…·è°ƒç”¨æ•°ç¼©æ”¾ Advantage

### 3.5 å¥–åŠ±å‡½æ•°

**å¥–åŠ±å…¬å¼**ï¼ˆç»“åˆ ParallelSearch + SWE-grepï¼‰ï¼š
```python
R = r_o + r_d + r_s + r_f

# r_o: Weighted F1 (Î²=0.5)ï¼Œä¼˜å…ˆ Precisionï¼ˆSWE-grep æ–¹å¼ï¼‰
# r_d: åˆ†è§£å¥–åŠ± (Î»_d=0.15)
# r_s: æœç´¢æ•ˆç‡å¥–åŠ± (Î»_s=0.35)  
# r_f: æ ¼å¼å¥–åŠ± â†’ æ ¼å¼é”™ç›´æ¥ 0 åˆ†ï¼ˆSWE-grep æ–¹å¼ï¼‰
```

**r_o è®¡ç®—**ï¼ˆSWE-grep æ–¹å¼ï¼‰ï¼š
```python
def weighted_f1(pred_lines, gold_lines, beta=0.5):
    """Î² < 1 åå‘ Precisionï¼Œé¿å…ä¸Šä¸‹æ–‡æ±¡æŸ“"""
    precision = len(pred & gold) / len(pred) if pred else 0
    recall = len(pred & gold) / len(gold) if gold else 0
    if precision + recall == 0:
        return 0
    return (1 + beta**2) * precision * recall / (beta**2 * precision + recall)

r_o = 0.5 * weighted_f1(pred_files, gold_files) + 0.5 * weighted_f1(pred_lines, gold_lines)
```

**V2 å¥–åŠ±**ï¼ˆåŠ å…¥è¡Œå· F1ï¼‰ï¼š
```python
r = r_o_v2 + r_d + r_s + r_f

# r_o_v2: ä¸‰å±‚ F1ï¼ˆæ–‡ä»¶ + æ®µè½ + è¡Œï¼‰
# è¯¾ç¨‹å­¦ä¹ ï¼šåˆæœŸæ–‡ä»¶çº§ä¸»å¯¼ï¼ŒåæœŸè¡Œçº§ä¸»å¯¼
```

**V3 å¥–åŠ±**ï¼ˆåŠ å…¥ç½®ä¿¡åº¦ï¼‰ï¼š
```python
r = r_o_v2 + r_d + r_s + r_f + r_conf + r_eff

# r_conf: ç½®ä¿¡åº¦æ ¡å‡†å¥–åŠ±
# r_eff: åŠ¨æ€ç»ˆæ­¢æ•ˆç‡å¥–åŠ±
```

### 3.5 è®­ç»ƒæµç¨‹

```
SFT é˜¶æ®µï¼ˆç›‘ç£å¾®è°ƒï¼‰
â”œâ”€â”€ ç›®çš„ï¼šæ•™ä¼šæ¨¡å‹è¾“å‡ºæ­£ç¡®æ ¼å¼
â”œâ”€â”€ æ•°æ®ï¼šGPT-4o åˆæˆ
â””â”€â”€ è§„æ¨¡ï¼š5,000-10,000 æ¡

RL é˜¶æ®µï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰
â”œâ”€â”€ ç›®çš„ï¼šä¼˜åŒ–æ£€ç´¢è´¨é‡å’Œæ•ˆç‡
â”œâ”€â”€ ç®—æ³•ï¼šPPO æˆ– GRPO
â”œâ”€â”€ è§„æ¨¡ï¼š20,000-50,000 episodes
â””â”€â”€ æ¡†æ¶ï¼šVERL / OpenRLHF / è‡ªå»º
```

---

## å››ã€æ•°æ®æ–¹æ¡ˆ

### 4.1 æ•°æ®æ¥æº

| æ•°æ®é›† | ç”¨é€” | æ ·æœ¬é‡ |
|--------|------|--------|
| HotpotQA | è®­ç»ƒ + è¯„æµ‹ | 90K è®­ç»ƒ / 7K éªŒè¯ |
| NQ | è¡¥å……è®­ç»ƒ | å¯é€‰ |
| 2WikiMultiHopQA | è¯„æµ‹ | 12K |
| Musique | è¯„æµ‹ | 2.4K |

### 4.2 æ•°æ®åˆæˆæµç¨‹

**Step 1ï¼šä¸‹è½½åŸå§‹æ•°æ®**
```bash
# HotpotQA
wget http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_train_v1.1.json
wget http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_dev_distractor_v1.json
```

**Step 2ï¼šè®¾è®¡åˆæˆ Prompt**

```
ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ ‡æ³¨ä¸“å®¶ã€‚ç»™å®šä¸€ä¸ªé—®ç­”å¯¹ï¼Œè¯·ç”Ÿæˆï¼š
1. å­é—®é¢˜åˆ†è§£ï¼ˆç”¨ ## åˆ†éš”å¯å¹¶è¡Œçš„å­é—®é¢˜ï¼‰
2. æœç´¢è½¨è¿¹ï¼ˆæ¯è½®æœç´¢ä»€ä¹ˆï¼‰
3. æ˜¯å¦å¯å¹¶è¡Œï¼ˆTrue/Falseï¼‰
4. ç›¸å…³æ–‡æ¡£çš„è¡Œå·èŒƒå›´

è¾“å…¥ï¼š
é—®é¢˜ï¼š{question}
ç­”æ¡ˆï¼š{answer}
æ”¯æŒäº‹å®ï¼š{supporting_facts}
æ–‡æ¡£ï¼š{context}

è¾“å‡º JSON æ ¼å¼ï¼š
{
  "is_parallelizable": true/false,
  "sub_queries": ["å­é—®é¢˜1", "å­é—®é¢˜2"],
  "search_trajectory": [
    {"round": 1, "queries": ["query1", "query2"], "parallel": true},
    {"round": 2, "queries": ["query3"], "parallel": false}
  ],
  "line_references": [
    {"file": "doc1", "start": 10, "end": 15},
    {"file": "doc2", "start": 20, "end": 25}
  ]
}
```

**Step 3ï¼šåˆ†æ‰¹åˆæˆ**

| æ‰¹æ¬¡ | æ•°é‡ | ç›®çš„ | æˆæœ¬ |
|------|------|------|------|
| è¯•éªŒæ‰¹ | 100 æ¡ | éªŒè¯ Prompt è´¨é‡ | $1 |
| å°æ‰¹ | 500 æ¡ | SFT å¿«é€ŸéªŒè¯ | $5 |
| ä¸­æ‰¹ | 5,000 æ¡ | æ­£å¼ SFT | $50 |
| å¤§æ‰¹ | 10,000 æ¡ | å®Œæ•´è®­ç»ƒï¼ˆå¯é€‰ï¼‰ | $100 |

### 4.3 æ•°æ®è´¨é‡æ£€æŸ¥

```python
def validate_sample(sample):
    checks = {
        "has_subqueries": len(sample["sub_queries"]) > 0,
        "trajectory_valid": all(r["queries"] for r in sample["search_trajectory"]),
        "line_refs_valid": all(r["start"] < r["end"] for r in sample["line_references"]),
        "parallelizable_consistent": sample["is_parallelizable"] == (
            any(r["parallel"] for r in sample["search_trajectory"])
        )
    }
    return all(checks.values()), checks
```

---

## äº”ã€å®éªŒè®¡åˆ’

### 5.1 éªŒè¯å®éªŒï¼ˆV0ï¼‰

**ç›®æ ‡**ï¼šç”¨æœ€å°æˆæœ¬éªŒè¯æ–¹æ¡ˆå¯è¡Œæ€§

| é¡¹ç›® | é…ç½® |
|------|------|
| æ¨¡å‹ | Qwen3-0.6B |
| æ•°æ® | 500 æ¡åˆæˆæ•°æ® |
| è®­ç»ƒ | ä»… SFTï¼Œä¸åš RL |
| ç›®æ ‡ | æ¨¡å‹èƒ½è¾“å‡ºæ­£ç¡®æ ¼å¼ |
| æ—¶é—´ | 2-3 å¤© |
| GPU | 1x RTX 3090/4090 |

**æˆåŠŸæ ‡å‡†**ï¼š
- 90%+ æ ·æœ¬è¾“å‡ºæ ¼å¼æ­£ç¡®
- èƒ½è¯†åˆ«å¯å¹¶è¡Œå­é—®é¢˜
- æ— æ˜æ˜¾æ ¼å¼å´©å

### 5.2 åŸºçº¿å®éªŒï¼ˆV1ï¼‰

**ç›®æ ‡**ï¼šå¤ç° ParallelSearch æ ¸å¿ƒèƒ½åŠ›

| é¡¹ç›® | é…ç½® |
|------|------|
| æ¨¡å‹ | Qwen3-1.7B |
| æ•°æ® | 5,000 æ¡ SFT + RL |
| è®­ç»ƒ | SFT + PPO |
| ç›®æ ‡ | åœ¨ HotpotQA ä¸Šè¾¾åˆ°åˆç†æ€§èƒ½ |
| æ—¶é—´ | 1-2 å‘¨ |
| GPU | 2-4x RTX 3090/4090 |

**æˆåŠŸæ ‡å‡†**ï¼š
- HotpotQA EM > 30%ï¼ˆåŸå§‹ Qwen3-1.7B çº¦ 10%ï¼‰
- å¹³å‡æœç´¢è½®æ•° < 3
- å¯å¹¶è¡Œé—®é¢˜ä½¿ç”¨å¹¶è¡Œæœç´¢

### 5.3 è¡Œå·å®éªŒï¼ˆV2ï¼‰

**ç›®æ ‡**ï¼šåŠ å…¥è¡Œå·å¬å›èƒ½åŠ›

| é¡¹ç›® | é…ç½® |
|------|------|
| æ¨¡å‹ | Qwen3-1.7Bï¼ˆä» V1 ç»§ç»­ï¼‰ |
| æ•°æ® | ç›¸åŒæ•°æ®ï¼ŒåŠ å…¥è¡Œå·æ ‡æ³¨ |
| è®­ç»ƒ | RL with ä¸‰å±‚ F1 å¥–åŠ± |
| ç›®æ ‡ | è¡Œå· F1 > 0.5 |
| æ—¶é—´ | 1 å‘¨ |

### 5.4 ç½®ä¿¡åº¦å®éªŒï¼ˆV3ï¼‰

**ç›®æ ‡**ï¼šåŠ å…¥ç½®ä¿¡åº¦å’ŒåŠ¨æ€ç»ˆæ­¢

| é¡¹ç›® | é…ç½® |
|------|------|
| æ¨¡å‹ | Qwen3-1.7Bï¼ˆä» V2 ç»§ç»­ï¼‰ |
| æ•°æ® | åŠ å…¥ç½®ä¿¡åº¦æ ‡æ³¨ |
| è®­ç»ƒ | RL with ç½®ä¿¡åº¦æ ¡å‡†å¥–åŠ± |
| ç›®æ ‡ | ç½®ä¿¡åº¦æ ¡å‡†è¯¯å·® < 0.1 |
| æ—¶é—´ | 1 å‘¨ |

---

## å…­ã€è¯„æµ‹æ–¹æ¡ˆ

### 6.1 è¯„æµ‹æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | æ ·æœ¬é‡ | ç”¨é€” |
|--------|------|--------|------|
| HotpotQA (dev) | å¤šè·³ QA | 7,405 | ä¸»è¯„æµ‹ |
| 2WikiMultiHopQA | å¤šè·³ QA | 12,576 | æ³›åŒ–è¯„æµ‹ |
| NQ | å•è·³ QA | 3,610 | ç®€å•åœºæ™¯ |

### 6.2 è¯„æµ‹æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡ |
|------|------|------|
| **EM** | Exact Match | > 35% |
| **F1** | Token-level F1 | > 45% |
| **Line F1** | è¡Œå·å¬å› F1 (Î²=0.5) | > 0.5 |
| **Avg Rounds** | å¹³å‡æœç´¢è½®æ•° | < 2.5 |
| **Parallel Rate** | å¹¶è¡Œä½¿ç”¨ç‡ | > 60% |
| **Calibration Error** | ç½®ä¿¡åº¦æ ¡å‡†è¯¯å·® | < 0.1 |

### 6.3 å¯¹æ¯”åŸºçº¿

| åŸºçº¿ | æ¥æº | HotpotQA EM |
|------|------|-------------|
| Qwen3-1.7B (raw) | åŸå§‹æ¨¡å‹ | ~10% |
| Qwen2.5-3B (raw) | åŸå§‹æ¨¡å‹ | ~15% |
| GAP-3B | è®ºæ–‡æŠ¥å‘Š | 42.5% |
| Search-R1 | è®ºæ–‡æŠ¥å‘Š | 37.6% |

---

## ä¸ƒã€èµ„æºä¼°ç®—

### 7.1 è®¡ç®—èµ„æº

| é˜¶æ®µ | GPU éœ€æ±‚ | æ—¶é—´ |
|------|---------|------|
| æ•°æ®åˆæˆ | æ—  | 1-2 å¤© |
| V0 éªŒè¯ | 1x 3090 | 2-3 å¤© |
| V1 SFT | 1x 3090 | 1 å¤© |
| V1 RL | 2-4x 3090 | 3-5 å¤© |
| V2 RL | 2-4x 3090 | 3-5 å¤© |
| V3 RL | 2-4x 3090 | 3-5 å¤© |
| è¯„æµ‹ | 1x 3090 | 1 å¤© |

**æ€»è®¡**ï¼šçº¦ 2-4 å‘¨ï¼Œéœ€è¦ 2-4 å¼  3090/4090

### 7.2 API æˆæœ¬

| ç”¨é€” | è°ƒç”¨é‡ | æˆæœ¬ |
|------|--------|------|
| è¯•éªŒåˆæˆ | 100 æ¡ | $1 |
| å°æ‰¹åˆæˆ | 500 æ¡ | $5 |
| æ­£å¼åˆæˆ | 5,000 æ¡ | $50 |
| æ‰©å±•åˆæˆ | 10,000 æ¡ | $100 |

**æ€»è®¡**ï¼š$50-150

---

## å…«ã€é£é™©ä¸åº”å¯¹

| é£é™© | æ¦‚ç‡ | å½±å“ | åº”å¯¹ |
|------|------|------|------|
| 1.7B å®¹é‡ä¸è¶³ | ä¸­ | é«˜ | å‡çº§åˆ° 3B |
| åˆæˆæ•°æ®è´¨é‡å·® | ä¸­ | ä¸­ | å¤šè½®è¿­ä»£ Prompt |
| RL è®­ç»ƒä¸ç¨³å®š | é«˜ | ä¸­ | å‚è€ƒ SWE-grep ç¨³å®šæ€§æŠ€å·§ |
| æ— æ³•è¶…è¶Š GAP | ä¸­ | ä½ | å®šä½ä¸º"æœ€å°å¼€æºå¹¶è¡Œæ£€ç´¢æ¨¡å‹" |
| è¡Œå·æ ‡æ³¨å›°éš¾ | ä¸­ | ä¸­ | ç®€åŒ–ä¸ºæ®µè½çº§åˆ« |

---

## ä¹ã€é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | æ—¶é—´ | äº¤ä»˜ç‰© |
|--------|------|--------|
| M1ï¼šæ•°æ®å‡†å¤‡ | ç¬¬ 1 å‘¨ | 500 æ¡éªŒè¯æ•°æ® + 5,000 æ¡è®­ç»ƒæ•°æ® |
| M2ï¼šV0 éªŒè¯ | ç¬¬ 1 å‘¨ | æ ¼å¼éªŒè¯é€šè¿‡çš„ 0.6B æ¨¡å‹ |
| M3ï¼šV1 åŸºçº¿ | ç¬¬ 2-3 å‘¨ | å¹¶è¡Œæ£€ç´¢èƒ½åŠ›çš„ 1.7B æ¨¡å‹ |
| M4ï¼šV2 è¡Œå· | ç¬¬ 3-4 å‘¨ | æ”¯æŒè¡Œå·å¬å›çš„æ¨¡å‹ |
| M5ï¼šV3 ç½®ä¿¡åº¦ | ç¬¬ 4-5 å‘¨ | å®Œæ•´åŠŸèƒ½æ¨¡å‹ |
| M6ï¼šå¼€æºå‘å¸ƒ | ç¬¬ 5-6 å‘¨ | æ¨¡å‹ + ä»£ç  + æŠ€æœ¯æŠ¥å‘Š |

---

## åã€æ‰§è¡Œè¿›åº¦

### å½“å‰çŠ¶æ€ï¼šğŸŸ¢ æ‰§è¡Œä¸­

| ä»»åŠ¡ | çŠ¶æ€ | å¤‡æ³¨ |
|------|------|------|
| 1. åˆ›å»ºé¡¹ç›®ç»“æ„ | âœ… | å®Œæˆ |
| 2. ä¸‹è½½ HotpotQA | âœ… | 90,447 è®­ç»ƒ + 7,405 éªŒè¯ |
| 3. è®¾è®¡åˆæˆ Prompt | âœ… | `src/data_synthesis/synthesis_prompt.py` |
| 4. åˆæˆ 100 æ¡è¯•éªŒæ•°æ® | â³ å¾…æ‰§è¡Œ | éœ€è¦ OPENAI_API_KEY |
| 5. æ£€æŸ¥æ•°æ®è´¨é‡ | â³ å¾…å¼€å§‹ | - |

### ä¸‹ä¸€æ­¥ä»»åŠ¡

1. **ä¼˜åŒ– Promptï¼ˆå¦‚éœ€è¦ï¼‰**
2. **åˆæˆ 500 æ¡æ•°æ®**
3. **å‡†å¤‡ SFT è®­ç»ƒè„šæœ¬**

---

## é™„å½• Aï¼šå…³é”®è¶…å‚æ•°

### SFT è¶…å‚æ•°

```yaml
model: Qwen/Qwen3-1.7B
learning_rate: 2e-5
batch_size: 8
gradient_accumulation_steps: 4
epochs: 3
warmup_ratio: 0.1
max_length: 4096
```

### RL è¶…å‚æ•°ï¼ˆå‚è€ƒ ParallelSearchï¼‰

```yaml
algorithm: PPO
learning_rate: 1e-6
batch_size: 32
rollout_batch_size: 64
epochs_per_update: 4
clip_range: 0.2
value_loss_coef: 0.5
entropy_coef: 0.01
max_grad_norm: 0.5

# å¥–åŠ±æƒé‡
lambda_d: 0.15  # åˆ†è§£å¥–åŠ±
lambda_s: 0.35  # æœç´¢æ•ˆç‡
lambda_f: 0.10  # æ ¼å¼å¥–åŠ±
```

---

## é™„å½• Bï¼šé¡¹ç›®ç»“æ„

```
LightningGrep/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # åŸå§‹æ•°æ®é›†
â”‚   â”œâ”€â”€ synthetic/           # åˆæˆæ•°æ®
â”‚   â””â”€â”€ processed/           # å¤„ç†åæ•°æ®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_synthesis/      # æ•°æ®åˆæˆè„šæœ¬
â”‚   â”œâ”€â”€ training/            # è®­ç»ƒä»£ç 
â”‚   â”‚   â”œâ”€â”€ sft.py
â”‚   â”‚   â””â”€â”€ rl.py
â”‚   â”œâ”€â”€ evaluation/          # è¯„æµ‹ä»£ç 
â”‚   â””â”€â”€ inference/           # æ¨ç†ä»£ç 
â”œâ”€â”€ configs/                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ scripts/                 # è¿è¡Œè„šæœ¬
â”œâ”€â”€ experiments/             # å®éªŒè®°å½•
â””â”€â”€ docs/                    # æ–‡æ¡£
```

---

**æ–‡æ¡£çŠ¶æ€**ï¼šå¾…æ‰§è¡Œ
**ä¸‹ä¸€æ­¥**ï¼šç¡®è®¤æ–¹æ¡ˆåå¼€å§‹æ‰§è¡Œ
